%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                       %%
%%     LaTeX + CTeX 《应用概率统计》论文模板, 只针对 A4 纸中文稿.        %%
%%                                                                       %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%            中文稿 文章模板：A4 纸, 五号字, 单列              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[a4paper,c1size,onecolumn,twoside,cap,Chinese]{APSart}
\usepackage{listings} 
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{amsmath} 
\usepackage{algpseudocode}
\graphicspath{{figs/}}
\floatname{algorithm}{Class} 
\begin{document}

\setcounter{page}{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%------------------ 编辑部提供的信息 ------------------------%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\pubvol}{xx}         % 卷号
\newcommand{\enpubvol}{xx}       % 卷号
\newcommand{\pubno}{x}           % 期号
\newcommand{\enpubno}{x}         % 期号
\newcommand{\pubyear}{20xx}      % 出版年份
\newcommand{\enpubyear}{20xx}    % 出版年份
\newcommand{\pubmonth}{xx}       % 出版月份
\newcommand{\enpubmonth}{xx}     % 出版月份
\newcommand{\ksym}{xxx}          % 开始页码
\newcommand{\jsym}{xxx}          % 结束页码
\newcommand{\receivedate}{本文XXXX年XX月XX日收到} % 论文收到日期
\newcommand{\modifydate}{XXXX年XX月XX日收到修改稿}% 论文修改日期
\newcommand{\doino}{10.3969/j.issn.1001-4268.20xx.0x.0xx} % doi号
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%-------------------- 作者提供的信息 ------------------------%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\runcnauthors}{~} %超过两个作者的请用：第一作者姓名~等
\newcommand{\cnfirstauthor}{陈越琦}
\newcommand{\cnsecondauthor}{刘威}
\newcommand{\cnthirdauthor}{杨杰才}
\newcommand{\cnfourthauthor}{周子博}
\newcommand{\cnfirstinst}{121160005 ~~Yueqichen.0x0@gmail.com}
\newcommand{\cnsecondinst}{131220085 ~~liuwei13cs@smail.nju.edu.cn}
\newcommand{\cnthirdinst}{131220115 ~~mark\_grove@qq.com}
\newcommand{\cnfourthinst}{121250229 ~~441842096@qq.com}
\newcommand{\cntitle}{大数据实验2---倒排索引~实验报告}
\newcommand{\cnkeywords}{Hadoop、倒排索引、全局排序、TF-IDF}
\newcommand{\cnclassno}{O212.xx} % 中图分类号
%%
\newcommand{\enfirstauthor}{FIRST Name}
\newcommand{\ensecondauthor}{SECOND Name}
\newcommand{\enfirstinst}{First Author's Working Unit $($Up to Department$)$, Province, 
Zip Code, China}
\newcommand{\ensecondinst}{Second Author's Working Unit $($Up to Department$)$, Province, 
Zip Code, China}
\newcommand{\entitle}{English Title}
\newcommand{\enkeywords}{keyword 1; keyword 2; ......}
\newcommand{\amsno}{62Nxx} % AMS Subject Claassification
%%
%% 中文摘要
\newcommand{\cnabstract}{摘要内容.}
%% 英文摘要
\newcommand{\enabstract}{The abstract comes here.}
\newcommand{\fundinfo}{XXXX基金资助(12345678).}
\newcommand{\authorsinfo}{陈越琦：121160005 Yueqichen.0x0@gmail.com~~~~~刘威：131220085  liuwei13cs@smail.nju.edu.cn}
\newcommand{\authorsinfoo}{杨杰才：121160005 mark\_grove@qq.com~~~~~周子博：121250229 441842096@qq.com}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%        文章正文                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{\zihao{3}\bf{\cntitle}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 作者姓名与单位：三种形式中选一种
% 后面英文摘要中的名字和单位同样处理
% ---------------------
% 第一种形式: 单一作者
% ---------------------
%\author{\zihao{4}\fangsong{\cnfirstauthor}\\[-1pt]
%{\zihao{-5}(\cnfirstinst)}}

% ---------------------
% 第二种形式: 同一单位 多个作者 -- 名字左右并列,
% ---------------------
%\author{\zihao{4}\fangsong{\cnfirstauthor\hy\hy\hy\cnsecondauthor}\\[-1pt]
%{\zihao{-5}(\cnfirstinst)}}

% ---------------------
% 第三种形式: 不同单位 多个作者 -- 名字与单位上下并列
% ---------------------
\author{\zihao{4}\fangsong{\cnfirstauthor}\\[-1pt]
{\zihao{-5}(\cnfirstinst)}\and
\zihao{4}\fangsong{\cnsecondauthor}\\[-1pt]
{\zihao{-5}(\cnsecondinst)}\and
\zihao{4}\fangsong{\cnthirdauthor}\\[-1pt]
{\zihao{-5}(\cnthirdinst)}\and
\zihao{4}\fangsong{\cnfourthauthor}\\[-1pt]
{\zihao{-5}(\cnfourthinst)}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\date{} % 这一行用来去掉默认的日期显示
\maketitle
\vspace{-6mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  中文摘要
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{minipage}[c]{13.5cm}
\zihao{-5}
\textbf{摘~~~要:}\quad 本次实验我们小组通过课堂上介绍的“带词频属性的文档倒排算法”，统计了词语的倒排索引并输出，按照要求输出了词语的平均出现次数，使用给定的小说数据集在集群上玩出了调试与测试。在此基础上，完成了两个选做任务：词语的全局排序与计算出每位作家每个词语的TF-IDF并输出。实验分别在本地进行了测试并提交到集群运行获得运行结果。\\
\\ \textbf{关键词:}\quad\cnkeywords
\end{minipage}
\footnote[1]{\scriptsize{\authorsinfo}}\vspace{2em}
\footnote[0]{\scriptsize{\authorsinfoo}}\vspace{2em}
\section{引\hy\hy\hy 言}
\noindent
倒排索引是文档检索系统中最常用的数据结构，被广泛的应用于全文搜索引擎。它主要用来存储某个单词（或词组），在一个文档或一组文档中的存储位置的映射，即提供了一种根据内容来查找文档的方式，由于不是根据文档来确定文档所包含的内容，而是进行了相反的操作，因而被称为倒排索引。在本次实验中，我们实现了带词频属性的文档倒排算法。除了实验任务外，我们还设计了两个MapReduce Job来进行选作内容的设计，分别进行以下两个工作：(1)对每个词语的平均出现次数进行全局排序，输出排序后的结果; (2)为每位作家、计算每个词语的TF-IDF。\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{实验环境与概述}
\noindent
本次实验的本地开发与测试环境如下：\\
\begin{center}
\includegraphics[height = 2.5cm]{2.png}\\
fig. 开发与测试环境
\end{center}
本次实验，我们完成了三个MapReduce任务的编写： (1)带词频属性的文档倒排算法. (2)对每个词语的平均出现次数进行全局排序. (3)为每位作家、计算每个词语的TF-IDF。
同时，我们也初步熟悉了集群的使用与在集群上执行任务的方法。\\下面几节我将详述实验的设计、测试与运行的结果。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{实验具体设计}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{带词频属性的文档倒排算法}
\subsubsection{总体设计}
\noindent
为完成InvertedIndex任务我们共设计了五个类： InvertedIndex, InvertedIndexMapper, InvertedIndexReducer, NewPartitioner, SumCombiner.\\
\\InvertedIndex是主类，负责启动配置作业，提交作业与获得完成结果的过程。\\NewParitioner类是自定义的patitioner。由于对键值对进行shuffle处理传送给合适的Reducer时，将按照Map所得的新的键(词语, 文档id)进行排序和选择Reducer，因而同一个term的键值对可能被分到不同Reducer，因而需要对paritioner进行自定义，使同一个term的键值对分到相同的Reducer，避免实验结果产生问题。
\\InvertedIndexMapper, InvertedIndexReducer, SumCombiner分别为Map,Reduce与Combine类。
\\下面我将叙述Map与Reduce的设计思路：
\\1. Map过程： Map过程首先分析输入的(key,value)对，即文档id与具体文档，使用java的字符串处理函数得到索引中需要的信息：词语，文档id。得到key：(词语\#文档id)(使用\#便于后面的切割)~与~value（即词语出现次数）：1。\\
2. Combine过程： 经过map方法处理后，Combine过程将key值相同的value值累加，得到一个词语在文档中的词频。\\
3. Reduce过程： 经过上述的两个过程后，Reduce过程将相同的词语的value值与词频属性组合成倒排引索文件的格式。\\
\\
MapReduce各阶段的K,V类型见下表：
\begin{center}
\includegraphics[height=2.6cm]{0.png}
\end{center}
\subsubsection{相关伪代码}
\noindent
\textbf{Mapper:}
\begin{algorithm}[H]
	{\bfseries Input :}~小说文档\\
	{\bfseries Output :}~键值对（词语\#文档id, 词频）
	\caption{$class~Mapper$}
	\begin{algorithmic}[1]
    	\Procedure {Map}{doc\_id j,doc d}
    	\State $F \leftarrow new AssociativeArray$
    	\For{$\bm{all}$ term $t$ in doc $d$ do}
    	\State $F\{t\} \leftarrow F\{t\} + 1$
    	\EndFor
    	\For{$\bm{all}$ term $t \in F$ do}
    	\State Emit($(pair<t,j>,frequency F\{t\})$)
    	\EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\noindent
\textbf{Combiner:}
\begin{algorithm}[H]
	{\bfseries Input :}~键值对（词语\#文档id, 词频）\\
	{\bfseries Output :}~键值对（词语\#文档id, 词频）
	\caption{$class~Combiner$}
	\begin{algorithmic}[1]
    	\Procedure {Reduce}{Text t, int value}
    	\State $Sum = 0$
    	\For{$\bm{all}$ value $val$ in Text $t$ do}
    	\State $Sum \leftarrow Sum + val$
    	\EndFor
    	\State Emit$(t, Sum)$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\noindent
\textbf{NewPartitioner:}
\begin{algorithm}[H]
	\caption{$class~NewPartitioner$}
	\begin{algorithmic}[1]
    	\Procedure {getPartition}{Text key, int value, int NumReduceTasks}
    	\State ~$term \leftarrow key.split("\#")[0]$\\
    	~~~~~~~\Return super.getPartition(term, value, NumReduceTasks)
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\noindent
\textbf{Reducer：}
\begin{algorithm}[H]
	{\bfseries Input :}~Combiner的结果\\
	{\bfseries Output :}~[词语]~平均出现次数~小说名: 词频
	\caption{$class~Reducer$}
	\begin{algorithmic}[1]
    	\Procedure {Setup}{~}
    		\State $t_{prev} \leftarrow \emptyset$
    		\State $P \leftarrow new PostingsList$
    	\EndProcedure
    	\Procedure {Reduce}{tuple$<t,n>, tf [f]$}
    		\State if $t \neq t_{prev}$ \^{} $t_{prev} \neq \emptyset$ then
    		\State ~~~~~Emit($t_{prev},P$)
    		\State ~~~~~$P$.Reset()
    		\State $P$.Add($<n,f>$)
    		\State $t_{prev} \leftarrow t$
    	\EndProcedure
    	\Procedure {Close}{~}
    		\State Emit$(t,P)$
    	\EndProcedure
  	\end{algorithmic}
\end{algorithm}
\subsection{对词语出现次数进行全局排序}
\subsubsection{任务设计思路}
\noindent
对词语出现次数进行全局排序是基于上面带词频属性的倒排索引的输出结果来操作的，将上面的输出按照平均出现次数由小到大进行排列。为完成这个任务，我们设计了ResultSort与ResultSortMapper两个类。该任务中，Mapper使用ResultSortMapper类,Paritioner\\与Reducer均使用默认类。\\
\\本任务的Map与Reduce设计如下：\\
1. Map过程： 从输入数据中使用字符串相关处理函数拆分出每个词语的平均出现次数作为key，原本的记录作为value。\\
2. Reduce过程： 将reduce task数目设为1，此时只有一个Reducer，也就是只有一个Partitioner，那么所有Map的输出都会经过一个Partitioner到一个Reducer里，在一个Reducer里会自动根据key的值即平均出现次数来排序，从而实现排序的目标，此时不会对每个键值对做任何具体的操作。\\
\\此时Map,Reduce各阶段的K,V类型见下表：
\begin{center}
\includegraphics[height=2.6cm]{14.png}
\end{center}
\subsubsection{相关伪代码}
\noindent
\textbf{Mapper的伪代码如下:}
\begin{algorithm}[H]
	{\bfseries Input :}~倒排索引记录\\
	{\bfseries Output :}~键值对（平均出现次数， 倒排索引记录）
	\caption{$class~Mapper$}
	\begin{algorithmic}[1]
    	\Procedure {Map}{InvertedIndexRecord record}
    	\State $average \leftarrow Word frequency in record$
    	\State Emit($average, record$)
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\subsection{为每位作家、计算每个词语的TF-IDF}
\subsubsection{任务设计思路}
\noindent
对于TF-IDF计算，我们在一定程度上借鉴了InvertedIndex的设计思想。\\
为完成TFIDF任务我们共设计了五个类： TFIDF, TFIDFMapper, TFIDFReducer, NewPartitioner, SumCombiner.\\
\\TFIDF是主类，负责启动配置作业，提交作业与获得完成结果的过程。\\NewParitioner类是自定义的patitioner。类似于InvertedIndex，由于在parition时要根据键的一部分作为依据进行分区选择reducer才能获得正确结果，因而我们重新设计了这个paritioner。
\\TFIDFMapper, TFIDFReducer, SumCombiner分别为Map,Reduce与Combine类。
\\下面我将叙述Map与Reduce的设计思路：
\\1. Map过程： Map过程首先分析输入的(key,value)对，即文档id与具体文档，使用java的字符串处理函数得到索引中需要的信息：词语，作者，小说名。从而得到键值对：~~key：(词语\#作者\#小说名)(使用\#便于后面的切割)~与~value（即词语出现次数）：1。\\
2. Combine过程： 经过map方法处理后，Combine过程将key值相同的value值累加，得到一个词语在文档中的词频。\\
3. Parition过程：将key中的(词语\#小说名)部分切割出来，以此为依据进行分区选择Reducer。\\
4. Reduce过程： 经过上述的两个过程后，Reduce过程将相同的词语与作者的value值与词频属性组合，从而计算出TF值与IDF值，将作者姓名，词语与TF值、IDF值组合成一条记录输出。\\
\\
MapReduce各阶段的K,V类型见下表：
\begin{center}
\includegraphics[height=2.4cm]{15.png}
\end{center}
\subsubsection{相关伪代码}
\noindent
\textbf{Mapper:}
\begin{algorithm}[H]
	{\bfseries Input :}~小说文档\\
	{\bfseries Output :}~键值对（词语\#文档\#小说名, 词频）
	\caption{$class~Mapper$}
	\begin{algorithmic}[1]
    	\Procedure {Map}{doc\_id j,doc d}
    	\State $author \leftarrow j.split()$
    	\State $doc\_name \leftarrow j.split()$
    	\State $F \leftarrow new AssociativeArray$
    	\For{$\bm{all}$ term $t$ in doc $d$ do}
    	\State $F\{t\} \leftarrow F\{t\} + 1$
    	\EndFor
    	\For{$\bm{all}$ term $t \in F$ do}
    	\State Emit($(pair<t,author,doc\_name>,frequency F\{t\})$)
    	\EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\noindent
\textbf{Combiner:}
\begin{algorithm}[H]
	{\bfseries Input :}~键值对（词语\#作者\#小说名, 词频）\\
	{\bfseries Output :}~键值对（词语\#作者\#小说名, 词频）
	\caption{$class~Combiner$}
	\begin{algorithmic}[1]
    	\Procedure {Reduce}{Text t, int value}
    	\State $Sum = 0$
    	\For{$\bm{all}$ value $val$ in Text $t$ do}
    	\State $Sum \leftarrow Sum + val$
    	\EndFor
    	\State Emit$(t, Sum)$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\noindent
\textbf{NewPartitioner:}
\begin{algorithm}[H]
	\caption{$class~NewPartitioner$}
	\begin{algorithmic}[1]
    	\Procedure {getPartition}{Text key, int value, int NumReduceTasks}
    	\State ~$word \leftarrow key.split("\#")[0]$
    	\State ~$author\_name \leftarrow key.split("\#")[1]$
    	\State ~$term \leftarrow word + author\_name$\\
    	~~~~~~~\Return super.getPartition(term, value, NumReduceTasks)
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\noindent
\textbf{Reducer：}
\begin{algorithm}[H]
	{\bfseries Input :}~Combiner的结果key与value\\
	{\bfseries Output :}~[作者，词语]~~TF-IDF
	\caption{$class~Reducer$}
	\begin{algorithmic}[1]
    	\Procedure {Reduce}{tuple$<t,author,doc\_name>, tf [f]$}
    		\State TF calculate
    		\State if $t \neq t_{prev}$ \^{} $t_{prev} \neq \emptyset$ then
    		\State ~~~~~~the number of files count
    		\State ~~~~~~IDF calculate
    		\State ~~~~~~Emit($t_{prev},P$)
    		\State ~~~~~~$P$.Reset()
    		\State $P$.Add($<author,TF,IDF>$)
    		\State $t_{prev} \leftarrow t$
    	\EndProcedure
    	\Procedure {Close}{~}
    		\State Emit$(t,P)$
    	\EndProcedure
  	\end{algorithmic}
\end{algorithm}
\section{实验测试与运行结果}
\noindent
\subsection{JAR包执行方式说明}
\noindent
1. 使用IDE或者javac指令进行编译，导出各个jar文件\\
2. 使用scp指令将jar包传送到服务器。\\
3. 使用ssh登录到服务器\\
4. 使用hadoop jar InvertedIndex.jar InvertedIndex /data/wuxia\_novels InvertedIndexoutput指令执行InvertedIndex.jar\\
5. 使用hadoop jar ResultSort.jar ResultSort InvertedIndexoutput ResultSortoutput指令以上面的执行结果为输入数据来执行ResultSort.jar\\
6. 使用hadoop jar TFIDF.jar TFIDF /data/wuxia\_novels TFIDFoutput指令执行TFIDF.jar
\subsection{实验运行结果展示}
\noindent
我们的程序均首先在本地做了简单的测试后提交到集群进行运行。\\
在集群上运行的结果如下：\\
\begin{itemize}[leftmargin=*]
\item 带词频属性的文档倒排算法InvertedIndex任务的运行结果：
该任务的输出结果在HDFS上的存放路径为：hdfs://master01:9000/user/2016st21/Lab2/InvertedIndexoutput .\\
该任务在集群上对全部数据集运行的结果的部分截图如下（输出格式为[词语] \\TAB 平均出现次数，小说1:词频；小说2:词频；小说3:词频；...；小说N:词频）：
\begin{center}
\includegraphics[height = 7cm]{4.png}
\includegraphics[height = 7cm]{5.png}
\end{center}

\item 对词语的平均出现次数进行排序的ResultSort任务的运行结果：
该任务的输出结果在HDFS上的存放路径为：hdfs://master01:9000/user/2016st21/Lab2/InvertedIndexoutput .\\
该任务在集群上对全部数据集运行的结果的部分截图如下（输出格式为 平均出现次数 \\TAB 原纪录）：
\begin{center}
\includegraphics[height = 7.5cm]{6.png}\\
~\\
\includegraphics[height = 7.5cm]{7.png}
\end{center}

\item 为每位作家、每个词语计算TF-IDF值的任务的运行结果：
该任务的输出结果在HDFS上的存放路径为：hdfs://master01:9000/user/2016st21/Lab2/TFIDFoutput .\\
该任务在集群上对全部数据集运行的结果的部分截图如下（输出格式为:~[作家] TAB 词语,~~TF值,~~IDF值）：
\begin{center}
\includegraphics[height = 7cm]{19.png}
\end{center}

\item “江湖”、“风雪”两个词语的输出结果如下：
\begin{center}
\includegraphics[height = 10cm]{8.png}\\
“江湖”的输出结果\\
~\\ \includegraphics[height = 3.8cm]{9.png}\\
“风雪”的输出结果
\end{center}
从上面的结果可以看到，不出意料地江湖基本出现在了所有的武侠小说之中，正所谓“人在江湖，身不由己”。
\end{itemize}
本实验在集群上执行MapReduce Job后获得的执行报告如下：
\begin{itemize}[leftmargin=*]
\item 在集群All Application（ http://114.212.190.91:8088/ ） 的WebUI页面中查看Job的执行状态的截图如下：\\
\begin{center}
\includegraphics[height = 9cm]{10.png}
\includegraphics[height = 2.5cm]{16.png}
\end{center}
\item 在WebUI页面（http://114.212.190.91:19888/jobhistory）找到对应的job如下
\begin{center}
\includegraphics[height = 5cm]{11.png}
\includegraphics[height = 2.2cm]{17.png}
\end{center}
\item 根据Job ID链接进入Job详细页面，几个job的详细信息如下所示。
\begin{itemize}[leftmargin=*]
\item InvertedIndexTable：\\
\noindent
\begin{flushleft}
\includegraphics[height = 14cm]{12.png}
\end{flushleft}
\item ResultSort
\begin{flushleft}
\includegraphics[height = 14cm]{13.png}
\end{flushleft}
\item TFIDF
\begin{flushleft}
\includegraphics[height = 14cm]{18.png}
\end{flushleft}
\end{itemize}  
\end{itemize}
\subsection{查看实验结果后得出的一些结论}
\noindent
根据倒排索引得出来的结果，我们不难发现武侠小说中关于词频的一些规律：
\begin{itemize}
\item	纯阿拉伯数字类出现的较多，是最普遍的，这个毋庸置疑
\item	时间和物质量词类因为小说的不同，自然出现频率低，具有独占性，对于搜索和定位来说是较优的关键字。
\item	出现了一些英文字母和单词，按常理来说中国的武侠小说是不应该含西文的。不过考虑到这些小说是网上下载的资源，因为大部分应该都是下载的链接信息或者出处信息。
\item	统计结果中出现的四字成语、古文俗语较多，频率大，这个不难看出小说行文的文采与流畅之处，毕竟都是大师作品，不是一些烂俗的网络小说。
\item	人名、地名等唯一性的词语频率较低，正常现象。
\item	的、地、得等助词出现的频率最高，符合汉语的表达习惯。
\end{itemize}
\section{实验总结}
\noindent
本次实验是大数据处理综合实验的第二次实验，在这次实验中我们完成了三个MapReduce任务的编写： (1)带词频属性的文档倒排算法. (2)对每个词语的平均出现次数进行全局排序. (3)为每位作家、计算每个词语的TF-IDF。通过本次实验，我们小组的人都对MapReduce算法设计与编程有了一定的了解，同时进一步加深了对前面所学的Hadoop MapReduce基本构架的理解。\\
\\这次实验各个任务中最主要的问题就是Map与Reduce过程的设计与(key,value)键值对类型的确定。在实验中，为确定Map与Reduce的设计与各个过程中键值对的类型转换过程，我们查阅了课本课件等相关资料，也在一起进行了一些讨论。在较好的确定各个过程key与value的类型及转换过程后，整个编程任务的完成就变得比较容易了。此外，在具体实现时，我们更进一步的了解了java字符串相关的操作函数。灵活使用这些函数，我们也得以方便地从输入文本与文件名中分割出想要的信息，例如作者的姓名与各个文件名。\\
\\本次实验是我们第一次较为深入地了解Hadoop MapReduce的算法设计与程序的编写和运行，整体完成较为顺利，也为后面的实验打下了较好的基础。
\vspace{6mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  参考文献
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zihao{-5}
\begin{thebibliography}{99}
%\setlength{\parskip}{0pt}  %段落之间的竖直距离
\addtolength{\itemsep}{-0.8 em} % 缩小参考文献间的垂直间距
  \bibitem{Book} 黄宜华. {\kaishu 深入理解大数据~大数据处理与编程实践}[M]. 北京: 机械工业出版社, 2014.7.
  \bibitem{Book-part} 作者. {\kaishu 章节名}[M]// 编者. {\kaishu 书名}. 出版地: 出版社, 年份: 起始页码.
  \bibitem{Conference} 作者. 文章题目[C]// 编者. {\kaishu 会议论文集名}. 出版地: 出版社, 年份: 起始页码.
  \bibitem{Wangl2000} Reckdahl K. {\it Using Import graphics in \LaTeX2e}[M]. 王磊, 译. [出版地不详]: [出版社不详], 2000.
  \bibitem{Huw2010} 胡伟. {\kaishu \LaTeX{}2$\varepsilon$完全学习手册}[M]. 北京: 清华大学出版社, 2011.
  \bibitem{Lip04} 李平. {\kaishu \LaTeX{}2$\varepsilon$及常用宏包使用指南}[M], 北京: 清华大学出版社, 2004.
  \bibitem{Sangdy01} 桑大勇, 王瑛. {\kaishu 科技文献排版系统: \LaTeX 入门与提高}[M]. 武汉: 武汉大学出版社, 2001.
  \bibitem{Chenzj02} 陈志杰, 赵书钦, 万福永. {\kaishu \LaTeX{}入门与提高}[M]. 北京: 高等教育出版社, 2002.
  \bibitem{Dengjs01} 邓建松, 彭冉冉, 陈长松. {\kaishu \LaTeX{}2$\varepsilon$科技排版指南}[M]. 北京: 科学出版社, 2001.
\end{thebibliography}
\clearpage
\end{document}
