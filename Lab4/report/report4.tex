%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                       %%
%%     LaTeX + CTeX 《应用概率统计》论文模板, 只针对 A4 纸中文稿.        %%
%%                                                                       %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%            中文稿 文章模板：A4 纸, 五号字, 单列              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[a4paper,c1size,onecolumn,twoside,cap,Chinese]{APSart}
\usepackage{listings} 
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{amsmath} 
\usepackage{algpseudocode}
\graphicspath{{figs/}}
\floatname{algorithm}{Class} 

\begin{document}

\setcounter{page}{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%------------------ 编辑部提供的信息 ------------------------%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\pubvol}{xx}         % 卷号
\newcommand{\enpubvol}{xx}       % 卷号
\newcommand{\pubno}{x}           % 期号
\newcommand{\enpubno}{x}         % 期号
\newcommand{\pubyear}{20xx}      % 出版年份
\newcommand{\enpubyear}{20xx}    % 出版年份
\newcommand{\pubmonth}{xx}       % 出版月份
\newcommand{\enpubmonth}{xx}     % 出版月份
\newcommand{\ksym}{xxx}          % 开始页码
\newcommand{\jsym}{xxx}          % 结束页码
\newcommand{\receivedate}{本文XXXX年XX月XX日收到} % 论文收到日期
\newcommand{\modifydate}{XXXX年XX月XX日收到修改稿}% 论文修改日期
\newcommand{\doino}{10.3969/j.issn.1001-4268.20xx.0x.0xx} % doi号
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%-------------------- 作者提供的信息 ------------------------%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\runcnauthors}{~} %超过两个作者的请用：第一作者姓名~等
\newcommand{\cnfirstauthor}{陈越琦}
\newcommand{\cnsecondauthor}{刘威}
\newcommand{\cnthirdauthor}{杨杰才}
\newcommand{\cnfirstinst}{121160005 ~~Yueqichen.0x0@gmail.com}
\newcommand{\cnsecondinst}{131220085 ~~liuwei13cs@smail.nju.edu.cn}
\newcommand{\cnthirdinst}{131220115 ~~mark\_grove@qq.com}
\newcommand{\cntitle}{大数据实验4--图的三角形计数~实验报告}
\newcommand{\cnkeywords}{Hadoop、有向图、社交网络、局部关系图}
\newcommand{\cnclassno}{O212.xx} % 中图分类号
%%
\newcommand{\enfirstauthor}{FIRST Name}
\newcommand{\ensecondauthor}{SECOND Name}
\newcommand{\enfirstinst}{First Author's Working Unit $($Up to Department$)$, Province, 
Zip Code, China}
\newcommand{\ensecondinst}{Second Author's Working Unit $($Up to Department$)$, Province, 
Zip Code, China}
\newcommand{\entitle}{English Title}
\newcommand{\enkeywords}{keyword 1; keyword 2; ......}
\newcommand{\amsno}{62Nxx} % AMS Subject Claassification
%%
%% 中文摘要
\newcommand{\cnabstract}{摘要内容.}
%% 英文摘要
\newcommand{\enabstract}{The abstract comes here.}
\newcommand{\fundinfo}{XXXX基金资助(12345678).}
\newcommand{\authorsinfo}{陈越琦：121160005 Yueqichen.0x0@gmail.com~~~~~刘威：131220085  liuwei13cs@smail.nju.edu.cn}
\newcommand{\authorsinfoo}{杨杰才：121160005 mark\_grove@qq.com}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%        文章正文                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{\zihao{3}\bf{\cntitle}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 作者姓名与单位：三种形式中选一种
% 后面英文摘要中的名字和单位同样处理
% ---------------------
% 第一种形式: 单一作者
% ---------------------
%\author{\zihao{4}\fangsong{\cnfirstauthor}\\[-1pt]
%{\zihao{-5}(\cnfirstinst)}}

% ---------------------
% 第二种形式: 同一单位 多个作者 -- 名字左右并列,
% ---------------------
%\author{\zihao{4}\fangsong{\cnfirstauthor\hy\hy\hy\cnsecondauthor}\\[-1pt]
%{\zihao{-5}(\cnfirstinst)}}

% ---------------------
% 第三种形式: 不同单位 多个作者 -- 名字与单位上下并列
% ---------------------
\author{\zihao{4}\fangsong{\cnfirstauthor}\\[-1pt]
{\zihao{-5}(\cnfirstinst)}\and
\zihao{4}\fangsong{\cnsecondauthor}\\[-1pt]
{\zihao{-5}(\cnsecondinst)}\and
\zihao{4}\fangsong{\cnthirdauthor}\\[-1pt]
{\zihao{-5}(\cnthirdinst)}\and
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\date{} % 这一行用来去掉默认的日期显示
\maketitle
\vspace{-6mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  中文摘要
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{minipage}[c]{13.5cm}
\zihao{-5}
\textbf{摘~~~要:}\quad 本次实验我们小组通过课堂上所讲的Hadoop的网页排名图算法PageRank的相关内容的启发，完成了社交网络局部关系图的三角形计数任务。并在集群上使用Twitter数据集与Google +数据集分别进行三角形的数目统计任务。并完成了选作任务转换逻辑的替换工作，在集群上执行得到相应的结果。\\
\\ \textbf{关键词:}\quad\cnkeywords
\end{minipage}
\footnote[1]{\scriptsize{\authorsinfo}}\vspace{2em}
\footnote[0]{\scriptsize{\authorsinfoo}}\vspace{2em}
\section{引\hy\hy\hy 言}

一个社交网络可以看做是一张图。社交网络中的人对应于图的顶点；社交网络中的人际关系对应于图中的边。由一个社交网络抽象转换所成的无向图上便肯定存在大量的三角形。本次实验中，我们小组完成了社交网络局部关系图的三角形计数任务：(1)根据不同的逻辑(OR / AND)将有向图转换为无向图，(2)在无向图的基础上计算出三角形的个数，(3)并在集群上使用Twitter数据集与Google +数据集分别进行三角形的数目统计任务。\\

实验报告的第2节简要介绍实验环境和完成情况。第3节中将详细介绍实验各个部分的设计。测试与运行的结果留在第4节中展示。在第5节中总结实验内容和团队合作。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{实验环境与概述}
\noindent
本次实验的本地开发与测试环境如下：\\
\begin{center}
\includegraphics[height = 2.5cm]{2.png}
\caption{开发与测试环境}
\end{center}
本次实验，我们分别完成了以下工作：
\begin{enumerate}
\item 分别根据OR 和 AND 逻辑将输入文件中的有向图转换为无向图.
\item 统计图中已存在的边和构造三角形所需的边，并根据统计结果计算出无向图中存在的三角形个数.
\item 使用Driver程序将多个job合并.
\item 分别在Twitter 和Google+  数据集完成测试。
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{实验具体设计}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{必做部分（OR逻辑转换）}
\subsubsection{总体设计}
\noindent
为完成在OR逻辑转换下的图的三角形计数，我们总共设计了两个MapReduce程序顺序执行来完成这一任务：
\begin{itemize}
\item DigraphToUngraph: 读入输入文件根据转换逻辑构造无向边，并统计出每一个顶点的相邻顶点并输出到HDFS.
\item InNeed: 统计图中已有的边与构造三角形所需边，根据所需边与已有边对应关系统计三角形数目并输出.
\end{itemize}
~\\
\textbf{DigraphToUngraph :}\\
为完成DigraphToUngraph任务我们共设计了个3类： 
\begin{enumerate}
\item DigraphToUngraphMapper类：分析输入文件的每一行, 切割出两个顶点的ID, 选择小的ID作为key, 大的ID作为value.
\item DigraphToUngraphReducer类：将key相同的ID所对应的value结合起来作为输出value, 获得该ID所代表的顶点的所有相邻顶点的ID,并输出到HDFS.
\item DigraphToUngraph类:主类，负责启动配置作业，提交作业与获得完成结果的过程.
\end{enumerate}

DigraphToUngraph的MapReduce各阶段的K,V类型见图2：
\begin{center}
\includegraphics[height=2.6cm]{0.png}
\caption{K,V类型表}
\end{center}
~\\
\textbf{InNeed :}\\
为完成InNeed任务我们共设计了3个类：
\begin{enumerate}
\item InNeedMapper类：分析DigraphToUngraph任务的输出文件，获得顶点ID与相邻顶点ID的对应关系，统计出图中已有的无向边，以及要构成三角形需存在的边\textbf{（具体判断方法：假设key为点A，从上一步结果得知其有两个相邻顶点B与C，则边BC就是构成三角形需要的边）}。将边的两个顶点ID的组合作为key， value为边的类型标记，存在的边标记为$\&$，需要的边标记为$\#$。
\item InNeedReducer类：查询Map的输出，如果边是已存在边，则记录其存在状态。如果类型是构成三角形需存在的边，且该边已经被标记为存在，则说明三角形存在，三角形数目加1。最后在cleanup函数中输出最终的三角形数目统计结果。
\item InNeed类：主类，负责启动配置作业，提交作业与获得完成结果的过程.
\end{enumerate}

InNeed的MapReduce各阶段的K,V类型见图3：
\begin{center}
\includegraphics[height=2.6cm]{1.png}
\caption{K,V类型表}
\end{center}

\subsubsection{DigraphToUngraph任务的伪代码}
\noindent
\textbf{DigraphToUngraphMapper:}
\begin{algorithm}[H]
	{\bfseries Input :}~输入文件\\
	{\bfseries Output :}~键值对（顶点ID, 顶点ID）
	\caption{$class~Mapper$}
	\begin{algorithmic}[1]
    	\Procedure {Map}{Text t}
    	\State vertex1\_ID $\leftarrow$ t.split
    	\State vertex2\_ID $\leftarrow$ t.split
    	\If   {vertex1\_ID$~<~$vertex2\_ID}
    	\State Emit((vertex1\_ID, vertex2\_ID))
    	\Else
    	\State Emit((vertex2\_ID, vertex1\_ID))
    	\EndIf
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\noindent
\textbf{DigraphToUngraphReducer：}
\begin{algorithm}[H]
	{\bfseries Input :}~键值对（顶点ID, 顶点ID）\\
	{\bfseries Output :}~顶点a所代表ID~~顶点a的相邻顶点所代表ID的序列
	\caption{$class~Reducer$}
	\begin{algorithmic}[1]
    	\Procedure {Reduce}{key: vertex\_smaller\_ID, value: vertex\_greater\_ID}
    		\State out $\leftarrow$  $\varnothing$
    		\For{value in values} 
			\State out $\leftarrow$ out + value: vertex\_greater\_ID
			\EndFor 
			\State Write(key: vertex\_smaller\_ID, out)
    	\EndProcedure
  	\end{algorithmic}
\end{algorithm}
\subsubsection{InNeed任务的伪代码}
\noindent
\textbf{InNeedMapper:}
\begin{algorithm}[H]
	{\bfseries Input :}~输入文件: 顶点ID~~~所有相邻顶点ID\\
	{\bfseries Output :}~键值对（边的ID序列， 边的种类标记）
	\caption{$class~Mapper$}
	\begin{algorithmic}[1]
    	\Procedure {Map}{Key keyID， Value value\_IDS}
    	\State IDs $\leftarrow$ value\_IDS.split
    	\For{ID in IDs} 
		\State Emit((keyID\#ID, \&))
		\EndFor 
		\For{ID1 in IDs} 
		\For{ID2 in IDs} 
		\State Emit((ID1\#ID2, \#))
		\EndFor 
		\EndFor 
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\noindent
\textbf{InNeedReducer：}
\begin{algorithm}[H]
	{\bfseries Input :}~键值对（边的ID序列， 边的种类标记）\\
	{\bfseries Output :}~该Reduce统计出的三角形数目
	\caption{$class~Reducer$}
	\begin{algorithmic}[1]
    	\Procedure {Reduce}{key: ID1\#ID2, values: \# or \&)}
    		\State NumTran $\leftarrow$  0
    		\State count $\leftarrow$  0
    		\State Exist $\leftarrow$  false
    		\For{value in values} 
			\If   {value~==~\&}
    		\State Exist $\leftarrow$ true
    	 	\EndIf
    	 	\If   {value~==~\#}
    		\State count $\leftarrow$ count~+~1
    	 	\EndIf
			\EndFor
			\If   {Exist == true}
			\State NumTran $\leftarrow$ NumTran~+~count	
			\EndIf
    	\EndProcedure
  	\end{algorithmic}
\end{algorithm}
\subsection{选做部分（AND逻辑转换）}
\subsubsection{总体设计}
当逻辑变为IF~~$(A\rightarrow B)$~AND~$(B\rightarrow A)$~~THEN~A-B时，我们考虑首先对图的边进行检查，若两个方向的边均存在，则说明该边存在。为做到这一点，我们考虑首先从输入数据中去除只有一个方向的边，经过这一处理后，便可以用必做部分的两个任务依次执行来完成这一任务。因而我们编写了StrongCheck这一任务，该任务读取输入数据，输出两个方向均存在边的顶点ID对的编号（按照顶点ID从小到大的顺序）。为实现该任务，我们采用了类似于前面InNeed任务的思路，读入一对顶点ID (A,B)，将顶点ID对 (A,B)设为存在，其反向(B,A)设为需要，从而在Reduce时检查(B,A)是否存在。通过以上方法即可将单方向的边去除。最后，将StrongCheck的输出文件作为输入依次执行必做部分所述的两个任务，即可完成欲执行的任务。\\~\\StrongCheck任务的具体设计如下：\\
为完成StrongCheck任务我们共设计了3个类：
\begin{enumerate}
\item StrongCheckMapper类：分析输入的txt文件，依次读取一对顶点ID，将两个顶点ID的组合作为key， 正向组合作为存在边，反向组合作为需求边。value为边的类型标记，存在的边标记为$\&$，需要的边标记为$\#$。
\item StrongCheckReducer类：查询Map的输出，如果边是已存在边，则记录其存在状态。如果边是需求边，则记录其需求状态。若一条边既是存在边也是需求边，则说明这一条边是双向的，应该转换为无向边，此时按照从小大顺序输出这一对顶点ID。
\item StrongCheck类：主类，负责启动配置作业，提交作业与获得完成结果的过程.
\end{enumerate}

StrongCheck的MapReduce各阶段的K,V类型见图3：
\begin{center}
\includegraphics[height=2.6cm]{3.png}
\caption{K,V类型表}
\end{center}

\subsubsection{StrongCheck任务的伪代码}
\noindent
\textbf{InNeedMapper:}
\begin{algorithm}[H]
	{\bfseries Input :}~输入文件: 顶点ID对\\
	{\bfseries Output :}~键值对（边的ID序列， 边的种类标记）
	\caption{$class~Mapper$}
	\begin{algorithmic}[1]
    	\Procedure {Map}{Key ID1，ID2}
		\State Emit((ID1\#ID2, \#))
		\State Emit((ID2\#ID1, \&))
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\noindent
\textbf{InNeedReducer：}
\begin{algorithm}[H]
	{\bfseries Input :}~键值对（边的ID序列， 边的种类标记）\\
	{\bfseries Output :}~键值对（较小顶点ID， 较大顶点ID）
	\caption{$class~Reducer$}
	\begin{algorithmic}[1]
    	\Procedure {Reduce}{key: ID1\#ID2, values: \# or \&)}
    		\State Need $\leftarrow$  false
    		\State Exist $\leftarrow$  false
    		\For{value in values} 
			\If   {value~==~\&}
    		\State Exist $\leftarrow$ true
    	 	\EndIf
    	 	\If   {value~==~\#}
    		\State Need $\leftarrow$ true
    	 	\EndIf
			\EndFor
			\If   {Exist == true~\textbf{AND}~Need == true}
			\State vertex\_smaller\_ID,~vertex\_greater\_ID $\leftarrow$ key.split	
			\State Emit((vertex\_smaller\_ID, vertex\_greater\_ID))
			\EndIf
    	\EndProcedure
  	\end{algorithmic}
\end{algorithm}
\subsection{对于Google+数据集所做的改进}
在Twitter数据集上运行时，我们采用了long来记录顶点的ID，这样也可以直接比较顶点ID的大小。而对于Google+数据集，很多顶点ID非常长，转换成数字远超long所能表示的范围，因而我们选择了采用String直接记录顶点ID对应的字符串，而不是转换为响应的整数表示。为了比较两个顶点ID，我们使用java的compareto方法来比较两个顶点ID字符串，这时比较的不是数字大小，而是依次比较各个字符的ASCII码的值。\\
此外，对于OR逻辑的程序在Google+数据集上运行，生成无向图的边非常多，使得运行时间大幅增加。在这里为了提升速度，我们给InNeed任务设置了8个Reduce任务，这样在Reduce过程中速度可以明显提升。不过此时，三角形数目将分成八个部分统计，最后需要将这八个数据加在一起获得总的三角形数目。
\newpage
\section{实验测试与运行结果}
\subsection{JAR包执行方式说明}
本次实验我们共编译并提交了三个JAR包： Driver1.jar~Driver\_op.jar~Driver\_G.jar。Driver1.jar用于在Twitter数据集上运行OR逻辑转换的程序，Driver\_G.jar用于在Google+数据集上运行OR逻辑转换的程序，Driver\_op.jar可用于运行Twitter与Google+两个数据集上AND逻辑转换的程序。这三个jar包的执行方式如下：
\begin{enumerate}
\item 	首先使用scp指令将jar包传送到服务器并使用SSH登录到服务器
\item	使用以下指令执行OR逻辑程序在Twitter数据集上运行的Driver： hadoop jar Driver1.jar Driver hdfs://master01:9000/data/graphTriangleCount/twitter\_graph\_v2.txt ./Lab4/output1 ./Lab4/output2
\item	使用以下指令执行OR逻辑程序在Google+数据集上运行的Driver： hadoop jar Driver\_G.jar Driver hdfs://master01:9000/data/graphTriangleCount/gplus\_combined.unique.txt ./Lab4/gp\_output1 ./Lab4/gp\_output2
\item	使用以下指令执行AND逻辑程序在Twitter数据集上运行的Driver：hadoop jar Driver\_op.jar Driver hdfs://master01:9000/data/graphTriangleCount/twitter\_graph\_v2.txt ./Lab4/op\_output1 ./Lab4/op\_output2 ./Lab4/op\_output3
\item	使用以下指令执行执行AND逻辑程序在Google+数据集上运行的Driver：hadoop jar Driver\_op.jar Driver hdfs://master01:9000/data/graphTriangleCount/gplus\_combined.unique.txt ./Lab4/op\_gpoutput1 ./Lab4/op\_gpoutput2 ./Lab4/op\_gpoutput3
\end{enumerate}
\subsection{实验运行结果展示}
\noindent
我们的程序均首先在本地做了简单的测试后提交到集群进行运行。\\
在集群上运行的结果如下：\\
各个任务统计出的三角形个数与运行时间见下面两表：
\begin{center}
\includegraphics[height = 2cm]{18.png}
\caption{OR逻辑程序}~\\
\includegraphics[height = 2cm]{19.png}
\caption{AND逻辑程序}
\end{center}
~\\各个人物具体的输出文件的截图如下：
\begin{itemize}[leftmargin=*]
\item OR逻辑程序在Twitter数据集上运行的的运行结果：
该任务的输出结果分为两部分，分别为DigraphToUngraph与InNeed的运行结果，其在HDFS上的存放路径分别为：hdfs://master01:9000/user/2016st21/Lab4/output1 与 hdfs://master01:9000/user/2016st21/Lab4/output1 . 其中后者存放最后统计的三角形的结果\\
该任务在集群上运行的结果的部分截图如下
\begin{center}
\includegraphics[height = 7cm]{4.png}
\includegraphics[height = 4cm]{5.png}
\end{center}
可以看到，最后统计出的三角形数目为13082506.

\item AND逻辑程序在Twitter数据集上运行的的运行结果：
该任务的输出结果分为三部分，分别为StrongCheck，DigraphToUngraph与InNeed的运行结果，其在HDFS上的存放路径分别为：hdfs://master01:9000/user/2016st21/Lab4/op\_output1， hdfs://master01:9000/user/2016st21/Lab4/op\_output2 与 hdfs://master01:9000/user/2016st21/Lab4/op\_output3 . 其中最后一个存放最后统计的三角形的结果\\
该任务在集群上运行的结果的部分截图如下
\begin{center}
\includegraphics[width = 14cm]{6.png}
\includegraphics[width = 14cm]{7.png}
\includegraphics[width = 14cm]{8.png}
\end{center}
可以看到，最后统计出的三角形数目为1818304，明显少于上一结果.


\item OR逻辑程序在Google+数据集上运行的的运行结果：
该任务的输出结果分为两部分，分别为DigraphToUngraph与InNeed的运行结果，其在HDFS上的存放路径分别为：hdfs://master01:9000/user/2016st21/Lab4/output1 与 hdfs://master01:9000/user/2016st21/Lab4/output2 . 其中后者存放最后统计的三角形的结果\\
该任务在集群上运行的结果的部分截图如下
\begin{center}
\includegraphics[width = 14cm]{16.png}
\includegraphics[width = 14cm]{17.png}
\end{center}
为加速Reduce过程，我们为InNeed作业设置了8个Reduce任务，将8个任务各自统计出的三角形数目相加，统计出总的三角形数目为13082506.

\item AND逻辑程序在Google+数据集上运行的的运行结果：
该任务的输出结果分为三部分，分别为StrongCheck，DigraphToUngraph与InNeed的运行结果，其在HDFS上的存放路径分别为：hdfs://master01:9000/user/2016st21/Lab4/op\_gpoutput1， hdfs://master01:9000/user/2016st21/Lab4/op\_gpoutput2 与 hdfs://master01:9000/user/2016st21/Lab4/op\_gpoutput3 . 其中最后一个存放最后统计的三角形的结果\\
该任务在集群上运行的结果的部分截图如下
\begin{center}
\includegraphics[width = 14cm]{9.png}
\includegraphics[width = 14cm]{10.png}
\includegraphics[width = 14cm]{11.png}
\end{center}
可以看到，最后统计出的三角形数目为27018510. 同样，该结果也明显少于上一个统计结果。
\end{itemize}
本实验在集群上执行MapReduce Job后获得的执行报告如下（由于本实验任务较多，我们只在文档中贴出OR逻辑程序在Twitter数据集上运行的任务的执行报告，其余Job的截图可在执行报告文件夹中查看）：
\begin{itemize}[leftmargin=*]
\item 在集群All Application（ http://114.212.190.91:8088/ ） 的WebUI页面中查看Job的执行状态的截图如下：\\
\begin{center}
\includegraphics[width = 14cm]{12.png}
\end{center}
\item 在WebUI页面（http://114.212.190.91:19888/jobhistory）找到对应的job如下
\begin{center}
\includegraphics[width = 14cm]{13.png}
\end{center}
\item 根据Job ID链接进入Job详细页面，几个job的详细信息如下所示。
\begin{itemize}[leftmargin=*]
\item Translation Di$->$Un：\\
\noindent
\begin{flushleft}
\includegraphics[width = 14cm]{14.png}
\end{flushleft}
\item needed edge
\begin{flushleft}
\includegraphics[width = 14cm]{15.png}
\end{flushleft}
\end{itemize}  
\end{itemize}
\subsection{程序性能及扩展性分析}
本次实验中，为了提高程序并行度，设置第一个作业的reducer任务的数量，使得第一个作业输出文件数量与reducer任务数相同。这样在第二个作业中就可以提高mapper任务的数量，使得两次作业的并行度都能够得到提高。但是由此带来了扩展性问题：如果reducer任务的数量过多，最后得到统计结果的文件也会相应增加，要获得真正的三角形数量必须要人工将这写文件中的统计结果相加，由此程序扩展性就存在问题。

此外，在作业执行过程中，我们发现存在作业执行严重的长尾延迟(Long Tail Latency)，被分配到slave3和slave7上的任务执行明显落后于其他任务的执行，导致作业的执行被严重拖后。我们认为长尾延迟存在的原因可能是中间数据划分不均匀，或者是因为其他作业的存在导致集群负载不均衡。



\newpage
\section{实验总结}
\subsection{实验内容总结}
本次实验是大数据处理综合实验平时实验的最后一次，在这次实验中我们完成了社交网络局部关系图的三角形计数任务：(1)根据不同的逻辑(OR / AND)将有向图转换为无向图，(2)在无向图的基础上计算出三角形的个数，(3)并在集群上使用Twitter数据集与Google +数据集分别进行三角形的数目统计任务。在实验中为了保持一致，图中所有的边都是以编号较小的点为key，编号较大的点(集)为value。

此外，针对不同的有向图无向图转换逻辑，本实验还分别编写了不同的Driver程序，实现多个MapReduce程序的批处理。更多关于程序运行性能和扩展性的分析在第4部分中详细叙述。因为本次实验的测试流程进行得比较晚，导致扎堆测试，浪费了比较多的时间，给程序的测试带来了很大的麻烦。在以后的实验中应该吸取教训，尽早开始测试。

\subsection{团队合作总结}
本次实验中，大家分工完成必做部分和选做部分以及实验报告的撰写。有了前几次合作的经验，本次的合作很顺利。


\vspace{6mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  参考文献
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zihao{-5}
\begin{thebibliography}{99}
%\setlength{\parskip}{0pt}  %段落之间的竖直距离
\addtolength{\itemsep}{-0.8 em} % 缩小参考文献间的垂直间距
  \bibitem{Book} 黄宜华. {\kaishu 深入理解大数据~大数据处理与编程实践}[M]. 北京: 机械工业出版社, 2014.7.
\end{thebibliography}
\clearpage
\end{document}
